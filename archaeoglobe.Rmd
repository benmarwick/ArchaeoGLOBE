---
title: "ArchaeoGLOBE trend analysis"
author: "Nick Gauthier"
date: "August 23, 2018"
output: 
  pdf_document: 
    highlight: pygments
    latex_engine: lualatex
  html_document: 
    highlight: pygments
    keep_md: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Sample analysis code for the ArchaeoGlobe database. Here we fit Generalized Additive Models (GAMs), a flexible form of nonlinear regression model capable of fitting smooth, time-varying trends to the ordered categorical ArchaeoGLOBE response data.

We model ordered categorical data using a latent variable following a logistic distribution. The model identifies a series of cut points, which correspond the the probabilities of the latent variable falling within each of our categories.

We fit two sets of trends. One trend is fitted to all the data simultaneously, representing the global trend across all archaeological regions. Then we fit region-level trends, which represent the deviation of each region from the global trend. By penalizing the "wiggliness" of the trend lines, we allow regional trends that don't significantly deviate from the global trend to be penalized to 0, effectively reducing that particular region to the global trend. This is a form of partial pooling, allowing the model to share information between groups and in so doing make the results less sensitive to regions with exceptionally low response rates.

After fitting the model, we can extract the region-specific diviations from the global trend, use a k-means clustering alogirithm to group together regions with similar trends, and map the results. We repeat this analysis for both self-reported expertise and perceived data quality.

# Setup

Import packages needed for analysis. We'll use packages from the `tidyverse`, such as `readr`, `dplyr`, and `ggplot2` for data import, processing, and plotting. We'll also use `mgcv` for fitting nonlinear trends to the data, and `kml` for clustering those trends. We'll use the `sf` package to help us plot shapefiles in a tidy context. Finally, we'll use `patchwork` to combine multiple ggplots in the same image.

```{r, message = FALSE}
library(tidyverse)
library(mgcv)
library(kml)
library(sf)

#install patchwork from github 
#devtools::install_github('thomasp85/patchwork')
library(patchwork)
```

## Data import

Read in the latest version of the ArchaeoGLOBE database and the regions shapefile.

```{r}
archaeoglobe <- read_csv('data/Survey_scrubbed_Aug20_IDs.csv')
regions <- st_read('data/Simplified_Regions2.shp')
```

## Analysis functions

Define some analysis functions that we'll be using repeatedly in the analysis, so that we don't have to keep copying and pasting the same lines of code.

This function subsets the data to highlight a variable of interest, and converts it from a wide to a long "tidy" format to make analysis and plotting easier.

```{r}
preprocess <- function(prefix, categories){
  archaeoglobe %>% # start with the full ArcheoGlobe data
    # drop columns not related to the variable of interest
    select(c(CONTRIBUTR:LAND_AREA, starts_with(prefix))) %>%
    gather(time, value, starts_with(prefix)) %>% # one value per row
    mutate(time = parse_number(time) * -1, # convert time period labels to years
           value = ordered(value, levels = categories),
           cat_num = as.numeric(value)) %>%
    mutate_if(is.character, as.factor) # convert characters to factors
}
```

This function takes a data frame produced by the above function and fits GAM to the global trend and local deviations for each region, accounting for inter-observer variability. This function takes as arguments a preprocessed data frame containing time slices, regions, contributors, and the ordered categorical response variable transformed to a numeric vector. 

```{r}
fit_model <- function(x, n_cats){
  bam(cat_num ~ 
        # this spline is for the global trend
        s(time, bs = 'cr', m = 2) + 
        # region-specific trends. bs = 'ts' and m = 1 
        # help penalize deviation from the global model
        s(time, by = REGION_LAB, bs = 'cs', m = 1) + 
        # add back in region-specific intercepts
        REGION_LAB +
        # model contributor as a random effect
        s(CONTRIBUTR, bs = 're', k = 252),
      data = x, # data frame to analyize
      family = ocat(R = n_cats), # ordered categorical with n levels
      # final 3 arguments just speed up the model fitting
      method = 'fREML',
      discrete = TRUE,
      nthreads = 2)
}
```

This function extracts the fitted splines for each region, ignoring factors such as the global trend and region and contributor specific intercepts so that the focus is on the shape of the local trends. Then it clusters these local deviations from the global trend into discrete clusters.

```{r}
extract_trends <-function(mod, n_clusters = 6){
  mod %>%
  plot(select = 0) %>% # plot for the side effect of printing smoothed fits
  .[2:147] %>% # extract the local trends
  map(~tibble(region =.$ylab, time = .$x, fit = c(.$fit))) %>% 
  bind_rows %>%
  mutate(fit = plogis(fit)) %>%
  spread(time, fit) %T>%
  set.seed(1000) %>%
  mutate(cluster = kmeans(.[,-1], n_clusters, iter.max = 100, nstart = 100)$cluster)
}
```

# Analysis

Now we use the functions defined above on the ArchaeoGlobe data. For convenience, first define a data frame that lists the prefixes of the variables we are interested in (e.g. "EXP" for expertise) and the levels of the ordered factors associated with each variable. This will make it easier to quickly focus on a specific variable. The `tribble` command is simply a way to make a data frame by row rather than column, which makes the code easier to read.

```{r}
response_levels <- tribble(
  ~prefix, ~categories,
  'EXP', c('None', 'Low', 'High'),
  'DQ', c('Unknown', 'Low', 'Moderate', 'Good'),
  'INAG', c('none', 'minimal (<1%)', 'common (1-20%)', 'widespread (>20%)')
)
```

Now map each of the above functions to each variable. This allows us to run the analysis for all variables of interest in a single goal, and save all the outputs in a tibble format for easy plotting. This will take a long time, so the results are cached by default for future use.

```{r, cache = TRUE}
trend_dat <- response_levels %>%
  mutate(data = map2(prefix, categories, ~preprocess(.x, .y)),
         n_cats = map_dbl(categories, length),
         mod = map2(data, n_cats, fit_model), 
         trends = map(mod, extract_trends))
```

# Results

Lastly, define a function to generate some nice multipanel plots for each analysis.

```{r}
plot_trends <- function(x, variable){
  p1 <- x$mod[[1]] %>%
    plot(select = 0) %>% # selects the global trend
    .[1] %>%
    map(~tibble(time = .$x, fit = c(.$fit), se = .$se)) %>%
    .[[1]] %>%
    ggplot(aes(time / 1000, plogis(fit)))+
    geom_line() +
    geom_line(aes(y = plogis(fit + 2 * se)), linetype = 2) +
    geom_line(aes(y = plogis(fit - 2 * se)), linetype = 2) +
    scale_y_continuous(limits = c(0,1)) +
    labs(title = 'A', x = 'Thousand years BP', y = variable) +
    theme_bw()

  p2 <- x$trends[[1]] %>%
    gather(time, value, 2:101) %>%
    ggplot(aes(as.numeric(time) / 1000, value, 
               group = region, color = as.factor(cluster))) +
    geom_line() +
    scale_color_brewer(palette = 'PuOr', guide = 'none') +
    facet_wrap(~cluster, nrow = 2) +
    labs(title = 'B', x = 'Thousand years BP', y = variable) +
    theme_minimal()
  
  p3 <- x$trends[[1]] %>%
    select(region, cluster) %>% # just select the columns of interest
    separate(region, c('extra', 'REGION_LAB'), sep = 'REGION_LAB') %>%
    left_join(select(x$data[[1]], REGION_ID:REGION_LAB)) %>%
    group_by(REGION_ID) %>%
    filter(row_number() == 1) %>%
    left_join(regions, ., by = c('Archaeo_ID' = 'REGION_ID')) %>% # join to the region shapes
    ggplot() + # plot
    geom_sf(aes(fill = as.factor(cluster)), size = .3, color = 'white', alpha = 0.9) +
    scale_fill_brewer(palette = 'PuOr', guide = 'none') +  
    labs(title = 'C') +
    theme_bw()
  
  # the patchwork command that prints the multipanel plots
  ((p1 | p2 ) + plot_layout(widths = c(1,2))) / 
    p3 + plot_layout(heights = c(1,2))
}
```

## Expertise
How does self-professed level of expertise vary in each region over time?

```{r, echo = FALSE, fig.width = 12, fig.height = 10, fig.cap = 'Global and regional trends in self-reported expertise. (A) Global trend (all regions) with 95% confidence interval. (B) Regional deviations from global trend, clustered via k-means. (C) Map of the local deviations from the global trend, same clusters as in B.'}
trend_dat[1, ] %>%
  mutate(trends = map(trends, 
                      ~mutate(., cluster = recode_factor(cluster, 
                                 `6` = '1', `4` = '2',`5` = '3', 
                                 `3` = '4', `1` = '5', `2` = '6')))) %>%
plot_trends('Expertise')
```

First we plot the global trend. We see a linear increase in self-reported expertise from 10ka BP up to 2ka BP, then a falloff continuing to the present day. This makes sense, as it points to both the increased frequency of preserved archaeological materials with time as well as the reduction in archaeological attention in periods with extensive historical records.

Now we cluster together the local deviations from the global trend using a k-means algorithm. We need to set the seed first to ensure reproduceability of the cluster solutions and ordering. The selection of 8 clusters is somewhat arbitrary, and is made simply based on visual comparisons of different cluster solutions with the goal of retaining as few clusters as possible while keeping their interpretations distinct.


Next we map out the archaeological regions, showing which region belongs to each cluster.


## Data Quality

```{r, echo = FALSE, fig.width = 12, fig.height = 10, fig.cap = 'Global and regional trends in perceived data quality. (A) Global trend (all regions) with 95% confidence interval. (B) Regional deviations from global trend, clustered via k-means. (C) Map of the local deviations from the global trend, same clusters as in B.'}
trend_dat[2, ] %>%
  mutate(trends = map(trends, ~mutate(., 
                                  cluster = recode_factor(cluster, 
                                 `6` = '1', `1` = '2',`5` = '3', 
                                 `3` = '4', `4` = '5', `2` = '6')))) %>%
plot_trends('Data Quality')
```

The global trend is more or less the same as the expertise data, with the peak in data quality occurring more recently than for expertise and with a less dramatic falloff leading to the present day. Also note the confidence interval for the global trend is generally wider than for the expertise responses.

## Intensive Agriculture

```{r, echo = FALSE, fig.width = 12, fig.height = 10, fig.cap = 'Global and regional trends in the areal extent of intensive agriculture. (A) Global trend (all regions) with 95% confidence interval. (B) Regional deviations from global trend, clustered via k-means. (C) Map of the local deviations from the global trend, same clusters as in B.'}
trend_dat[3, ] %>%
  mutate(trends = map(trends, ~mutate(.,
                                 cluster = recode_factor(cluster, 
                                 `1` = '1', `2` = '2',`5` = '3', 
                                 `4` = '4', `3` = '5', `6` = '6')))) %>%
plot_trends('Intensive Agriculture')
```

