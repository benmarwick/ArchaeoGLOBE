---
title: "archeoglobe"
author: "Nick Gauthier"
date: "August 23, 2018"
output: 
  html_document: 
    highlight: pygments
    keep_md: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Sample analysis code for the ArchaeoGlobe database.

## Setup
Import packages needed for analysis. We'll use packages from the `tidyverse`, such as `readr`, `dplyr`, and `ggplot2` for data import, processing, and plotting. The `sf` package will help us work with shapefiles in a tidy context.
```{r}
library(tidyverse)
library(sf)
# devtools::install_github("jbaileyh/geogrid")
library(geogrid)
library(mgcv)
```

## Data import
Read in the latest version of the ArchaeoGLOBE database.
```{r}
dat <- read_csv('../data/ArchaeoGLOBE_Public_Data_2018_08_14.csv')
```

Next import the regions shapefile.
```{r}
regions <- st_read('../data/ArchaeGLOBE_Regions.shp') %>%
  mutate(Archaeo_ID = as.factor(Archaeo_ID))
```

## Analysis of expertise
How does the self-professed level of expertise vary in each region over time?
First, make a dataset just of the expertise data.
```{r}
exp_dat <- dat %>%
  select(1:18) %>% # select the first 18 columns
  gather(time, expertise, 9:18) %>% # convert the data to long format, with one expertise value per row
  mutate(time = parse_number(time) * -1, # convert time period labels to years
         expertise = ordered(expertise, levels = c('None', 'Low', 'High')),
         exp_num = as.numeric(expertise),
         region = as.factor(REGION_LAB))
```

Before doing everything else, let's plot out the data.
```{r}
ggplot(exp_dat, aes(time, expertise, group = region)) +
  stat_smooth(geom='line', alpha=0.3, se=FALSE, method = 'loess') +
  facet_wrap(~WORLD_LAB) +
  theme_minimal()
```

The above plot might be somewhat misleading, because we aren't accounting for individual observer effects, such as observers who are more likely to enter high expertise regardless of region. Let's try fitting a multilevel model.

Inspiration for this analysis from here: https://cdn.rawgit.com/eric-pedersen/mgcv-esa-workshop/master/example-forest-health.html



Next fit some models.
First fit only a global smooth term. The first model fits only the global trend, the second fits a global trend w/ group-specific intercepts, and the third penalizes both the smooth term and the group-specific intercepts toward the global mean.

```{r fit_gam}
ctrl <- gam.control(nthreads = 3)
fit_gam <- function(x){
  gam(x, method = 'ML',
         family = ocat(R = 3),
         control = ctrl,
         data = exp_dat)
}
```

Now we write out a list of potential model structures, and fit gams using all of them. Calculate the AICs for each formula, link function combination, and reorder the amount from the lowest AIC
```{r exp_models}
exp_models <- c(
    "s(time) + s(region, bs = 're')",
    "s(time, region, bs = 'fs')",
    "s(time) + s(time, region, bs = 'fs')",
    "s(time, by = region) + s(region, bs = 're')"
   ) %>%
  paste('exp_num ~ ', .) %>%
  tibble(formula_chr = .) %>%
  mutate(formula = map(formula_chr, as.formula), 
         model = map(formula, fit_gam)) %>%
  mutate(aic = map_dbl(model, AIC)) %>%
  arrange(aic)
```
```{r}
saveRDS(exp_models, 'exp_models')
```

Compare the AICs of the result
```{r}
exp_models
```

```{r}
expand.grid(time = seq(-10000,2000, by = 500), region = exp_dat$region) %>%
  mutate(., pred = predict(exp_models[[2,3]], ., type = 'link')) %>%
  filter(region != "Northern Kazakhstan") %>%
  ggplot(aes(time, pred, group = region, color = region)) +
  geom_line(alpha = .4) +
  guides(color= FALSE)

expand.grid(time = seq(-10000,2000, by = 100), region = exp_dat$region) %>%
  mutate(., pred = predict(exp_models[[2,3]], ., type = 'link')) %>%
  filter(pred> 10)

expand.grid(time = seq(-10000,2000, by = 500), region = exp_dat$region) %>%
  mutate(., pred = predict(exp_models[[2,3]], ., type = 'link')) %>%
   ggplot(aes(time, pred, group = region, color = region)) +
  geom_line(alpha = .4) +
  guides(color= FALSE)

dat %>% filter(REGION_LAB == "Tunisia")
```

```{r}
mod8 <- gam(exp_num ~ s(period, WORLD_LAB, bs = 'fs'), 
            data = exp_dat, family = ocat(R = 3), 
            method = 'REML', select = F)
mod9 <- gam(exp_num ~ te(period, WORLD_LAB, bs = c('tp', 're')) + s(WORLD_LAB, bs = 're'), 
            data = exp_dat, family = ocat(R = 3), 
            method = 'REML', select = T)
```

```{r}
mod10 <- bam(exp_num ~ s(period, bs = 'cr', by = REGION_LAB) + s(REGION_LAB, bs = 're'), 
            data = exp_dat, family = ocat(R = 3), 
            select = T, nthreads = 4)
```



```{r}
#st_queen <- function(a, b = a) st_relate(a, b, pattern = 'F***T****')
#st_queen(regions)
#st_intersects(regions, sparse = TRUE)
neighb <- spdep::poly2nb(as(regions, 'Spatial'), row.names = regions$Archaeo_ID) %>%
  lapply(function(xx) regions$Archaeo_ID[xx] %>% factor(levels = levels(regions$Archaeo_ID))) %>%
  set_names(regions$Archaeo_ID)

ctrl <- gam.control(nthreads = 2)
mod5 <- gam(exp_num ~ te(period, REGION_ID, bs = c('cr', 'mrf'), k = c(10, 100), xt = list(nb = neighb)), 
            data = exp_dat, family = ocat(R = 3), method = 'REML',
            select = FALSE, control = ctrl)

mod6 <- gam(exp_num ~ s(period, bs = 'cr')  + s(REGION_ID, bs = 'mrf', k = 100, xt = list(nb = neighb)) + ti(period, REGION_ID, bs = c('cr', 'mrf'), k = c(10, 100), xt = list(nb = neighb)), 
            data = exp_dat, family = ocat(R = 3), method = 'REML',
            select = FALSE, control = ctrl)

plot(mod6)
test <- expand.grid(period = seq(-10000,2000, by = 100), REGION_ID = factor(1:146))
test %>%
  mutate(pred = predict(mod6, test, type = 'link')) %>%
  ggplot(aes(period, pred, group = REGION_ID, color = REGION_ID)) +
  geom_line(alpha = .4) +
  guides(color= FALSE)
```



## Plotting
Next let's explore some sample plots
```{r}
ggplot() + 
  geom_sf(data = regions) +
  theme_minimal() +
  ggtitle('ArchaeoGLOBE regions')
```

Next try plotting the estimated number of sites. First define an ordering for the number of sites estimate, to aid in plotting.
```{r}
n_sites <- c('< 50', '50-249', '250-499', '500-999', '> 1000')
```

Now, modify the `RN_SITES` column to be an ordered factor using the above sequence. Then calculate the most common response for each region, and plot the result
```{r}
dat %>% 
  select(REGION_ID, RN_SITES) %>% # just select the columns of interest
  mutate(RN_SITES = ordered(RN_SITES, levels = n_sites)) %>% # create an ordered factor
  group_by(REGION_ID) %>% # focus on each region separately
  count(RN_SITES) %>% # count the number of responses for each site number
  slice(which.max(n)) %>% # choose the most selected response for each region
  left_join(regions, ., by = c('Archaeo_ID' = 'REGION_ID')) %>% # join to the region shapes
  ggplot() + # plot
    geom_sf(aes(fill = RN_SITES), size=.3, color = 'white', alpha=0.9) +
    theme_minimal() +
    ggtitle('ArchaeoGLOBE regions', 'Estimated number of excavated sites')
```

```{r}
par(mfrow = c(8, 5), mar = c(0, 0, 2, 0))
for (i in 1:40) {
  new_cells <- calculate_grid(shape = regions, grid_type = "hexagonal", seed = i)
  plot(new_cells, main = paste("Seed", i, sep = " "))
}
```
```{r}
new_cells_hex <- calculate_grid(shape = regions, grid_type = "hexagonal", seed = 23)
resulthex <- assign_polygons(regions, new_cells_hex)

dat %>% 
  select(REGION_ID, RN_SITES) %>% # just select the columns of interest
  mutate(RN_SITES = ordered(RN_SITES, levels = n_sites)) %>% # create an ordered factor
  group_by(REGION_ID) %>% # focus on each region separately
  count(RN_SITES) %>% # count the number of responses for each site number
  slice(which.max(n)) %>% # choose the most selected response for each region
  left_join(resulthex, ., by = c('Archaeo_ID' = 'REGION_ID')) %>% # join to the region shapes
  ggplot() + # plot
    geom_sf(aes(fill = RN_SITES), size=.3, color = 'white', alpha=0.9) +
    theme_minimal() +
    ggtitle('ArchaeoGLOBE regions', 'Estimated number of excavated sites')
```

